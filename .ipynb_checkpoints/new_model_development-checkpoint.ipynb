{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5580468e-4214-44ee-bc9c-75f501be1892",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, recall_score,\n",
    "                            f1_score, roc_auc_score, auc, precision_recall_curve,\n",
    "                            matthews_corrcoef, mean_squared_error)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Set random state\n",
    "RANDOM_STATE = 778\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6eb16df-e439-4cfe-8068-8812c3151937",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/final_data/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0769a7fc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Functions to be used throughout notebook\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df = df.copy()\n",
    "\n",
    "    # Convert timestamp and ensure dates are sorted\n",
    "    df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "    df = df.sort_values('event_date').reset_index(drop=True)\n",
    "\n",
    "    # One-hot encode categorical columns\n",
    "    categorical_cols = ['vessel_info_flag', 'event_info_origin_port.iso', 'event_info_destination_port.iso']\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Define features and target\n",
    "    target = 'extended_loitering'\n",
    "    features = df.columns.difference([target, 'event_date'])\n",
    "\n",
    "    # Remove multicollinearity\n",
    "    corr_matrix = df[features].corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "    features = features.difference(to_drop)\n",
    "    df = df.drop(columns=to_drop)\n",
    "\n",
    "    return df, features, target\n",
    "\n",
    "\n",
    "# Model Evaluation metrics\n",
    "def evaluate_model(y_true, y_pred, y_pred_proba):\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'pr_auc': average_precision_score(y_true, y_pred_proba)\n",
    "    }\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return metrics, conf_matrix\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "df_processed, features, target = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe66cd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Initial Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e17d3c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Model training and evaluation function\n",
    "def train_and_evaluate_models(df, features, target, n_splits=5):\n",
    "    # Initialize TimeSeriesSplit with custom parameters\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits, max_train_size=None)\n",
    "\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=RANDOM_STATE, max_iter=1000),\n",
    "        'Decision Tree': DecisionTreeClassifier(class_weight='balanced', random_state=RANDOM_STATE),\n",
    "        'Random Forest': RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=RANDOM_STATE),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "\n",
    "    # Prepare data\n",
    "    X = df[features].values\n",
    "    y = df[target].values\n",
    "\n",
    "    # Store results\n",
    "    results = {model_name: [] for model_name in models.keys()}\n",
    "    confusion_matrices = {model_name: np.zeros((2, 2)) for model_name in models.keys()}\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Scale features within the fold\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            # Train model\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_val_scaled)\n",
    "            y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "            # Calculate metrics\n",
    "            metrics, conf_matrix = evaluate_model(y_val, y_pred, y_pred_proba)\n",
    "            results[model_name].append(metrics)\n",
    "            confusion_matrices[model_name] += conf_matrix\n",
    "\n",
    "    # Average results across folds\n",
    "    final_results = {}\n",
    "    for model_name in models.keys():\n",
    "        model_metrics = pd.DataFrame(results[model_name])\n",
    "        final_results[model_name] = model_metrics.mean()\n",
    "\n",
    "    return final_results, confusion_matrices\n",
    "\n",
    "\n",
    "# Function to plot confusion matrices\n",
    "def plot_confusion_matrices(confusion_matrices):\n",
    "    n_models = len(confusion_matrices)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for idx, (model_name, conf_matrix) in enumerate(confusion_matrices.items()):\n",
    "        if idx < len(axes):\n",
    "            sns.heatmap(conf_matrix, annot=True, fmt='g', ax=axes[idx])\n",
    "            axes[idx].set_title(f'{model_name} Confusion Matrix')\n",
    "            axes[idx].set_xlabel('Predicted')\n",
    "            axes[idx].set_ylabel('Actual')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Train and evaluate models\n",
    "results, confusion_matrices = train_and_evaluate_models(df_processed, features, target)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "fig = plot_confusion_matrices(confusion_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd671a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Refining - Iteration 1: CV split adjustments with fixed params for RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8dd2c8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                           f1_score, roc_auc_score, average_precision_score,\n",
    "                           confusion_matrix)\n",
    "\n",
    "\n",
    "def xgb_model(df, features, target, n_splits=5, n_iter=100):\n",
    "    \"\"\"\n",
    "    Optimize Gradient Boosting model using RandomizedSearchCV with time series split.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X = df[features].values\n",
    "    y = df[target].values\n",
    "\n",
    "    # Define parameter space\n",
    "    param_distributions = {\n",
    "        'classifier__n_estimators': [100, 300, 500, 700, 900],\n",
    "        'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        'classifier__max_depth': [3, 4, 5, 6, 7, 8, 10],\n",
    "        'classifier__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'classifier__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'classifier__scale_pos_weight': [1, 10, 25, 50, 75, 100],\n",
    "        'classifier__gamma': [0, 0.1, 0.2, 0.5, 1, 1.5, 2],\n",
    "        'classifier__min_child_weight': [1, 2, 3, 4, 5],\n",
    "    }\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', XGBClassifier(random_state=RANDOM_STATE, eval_metric='logloss'))\n",
    "    ])\n",
    "\n",
    "    # Initialize TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    # Initialize RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        cv=tscv,\n",
    "        scoring='average_precision',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fit RandomizedSearchCV\n",
    "    random_search.fit(X, y)\n",
    "\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "\n",
    "def evaluate_optimized_model(model, df, features, target, n_splits=5, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Lower threshold will increase recall (catch more actual extended loitering events), but decrease precision (more false positive)\n",
    "    \"\"\"\n",
    "    X = df[features].values\n",
    "    y = df[target].values\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    results = []\n",
    "    confusion_matrices = np.zeros((2, 2))\n",
    "    feature_importances = []\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Scaling not needed for XGBoost\n",
    "        X_train_scaled = X_train\n",
    "        X_val_scaled = X_val\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Collect feature importances\n",
    "        classifier = model.named_steps['classifier']\n",
    "        feature_importances.append(classifier.feature_importances_)\n",
    "\n",
    "        # Get probability predictions first\n",
    "        y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "        # Apply custom threshold to probabilities\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "        metrics, conf_matrix = evaluate_model(y_val, y_pred, y_pred_proba)\n",
    "        results.append(metrics)\n",
    "        confusion_matrices += conf_matrix\n",
    "\n",
    "    # Average metrics across folds\n",
    "    avg_metrics = pd.DataFrame(results).mean()\n",
    "\n",
    "    # Average feature importances across folds\n",
    "    avg_feature_importance = np.mean(feature_importances, axis=0)\n",
    "    feature_importance_df = pd.DataFrame(\n",
    "        avg_feature_importance,\n",
    "        index=features,\n",
    "        columns=['importance']\n",
    "    ).sort_values('importance', ascending=False)\n",
    "\n",
    "    return avg_metrics, confusion_matrices, feature_importance_df\n",
    "\n",
    "\n",
    "def plot_results(confusion_matrix, feature_importance):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix and feature importance.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='g', ax=ax1)\n",
    "    ax1.set_title('Confusion Matrix')\n",
    "    ax1.set_xlabel('Predicted')\n",
    "    ax1.set_ylabel('Actual')\n",
    "\n",
    "    # Plot top 15 feature importance\n",
    "    feature_importance.head(15).plot(kind='barh', ax=ax2)\n",
    "    ax2.set_title('Top 15 Feature Importance')\n",
    "    ax2.set_xlabel('Importance')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "best_split_data = {'pr_auc': 0, 'splits': None, 'metrics': None, 'conf_matrix': None, 'feature_importance': None}\n",
    "\n",
    "for splits in [3, 5, 7, 10]:\n",
    "    print(f\"\\nGetting best XGBoost model with {splits} CV splits...\")\n",
    "    best_model, best_params = xgb_model(df_processed, features, target, n_splits=splits)\n",
    "\n",
    "    print(f\"\\nBest parameters for {splits} CV splits:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param.replace('classifier__', '')}: {value}\")\n",
    "\n",
    "    metrics, conf_matrix, feature_importance = evaluate_optimized_model(\n",
    "        best_model, df_processed, features, target, n_splits=splits, threshold=0.5)\n",
    "\n",
    "    current_pr_auc = metrics.get('pr_auc', 0)\n",
    "    if current_pr_auc > best_split_data['pr_auc']:\n",
    "        best_split_data.update({\n",
    "            'pr_auc': current_pr_auc,\n",
    "            'splits': splits,\n",
    "            'metrics': metrics,\n",
    "            'conf_matrix': conf_matrix,\n",
    "            'feature_importance': feature_importance\n",
    "        })\n",
    "\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    print(metrics)\n",
    "\n",
    "# Display and plot the results for the best split\n",
    "print(\"\\nBest Split Based on pr_auc Score:\")\n",
    "print(f\"Number of CV Splits: {best_split_data['splits']}\")\n",
    "\n",
    "print(\"Best Model Performance Metrics:\")\n",
    "print(best_split_data['metrics'])\n",
    "\n",
    "fig = plot_results(best_split_data['conf_matrix'], best_split_data['feature_importance'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d0e1f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Refining - Iteration 2: Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e1e88",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optimized CV splits\n",
    "CV_SPLITS = 3\n",
    "\n",
    "def clean_params(best_params):\n",
    "    \"\"\"\n",
    "    Remove 'classifier__' prefix from parameter names.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        k.replace('classifier__', ''): v\n",
    "        for k, v in best_params.items()\n",
    "    }\n",
    "\n",
    "def perform_rfe_analysis(df, features, target, n_features_list):\n",
    "    \"\"\"\n",
    "    Perform RFE analysis with different feature set sizes using optimized XGBoost parameters.\n",
    "    \"\"\"\n",
    "    X = df[features].values\n",
    "    y = df[target].values\n",
    "\n",
    "    best_model, best_params = xgb_model(df_processed, features, target, n_splits=CV_SPLITS)\n",
    "\n",
    "    cleaned_params = clean_params(best_params)\n",
    "\n",
    "    # Initialize RFE classifier\n",
    "    base_classifier = XGBClassifier(random_state=RANDOM_STATE, **cleaned_params)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for n_features in n_features_list:\n",
    "        print(f\"\\nTesting feature set size: {n_features}\")\n",
    "\n",
    "        # Perform RFE with base classifier\n",
    "        rfe = RFE(estimator=base_classifier,\n",
    "                  n_features_to_select=n_features,\n",
    "                  step=1)\n",
    "        rfe.fit(X, y)\n",
    "\n",
    "        # Get selected features\n",
    "        selected_features = [f for f, selected in zip(features, rfe.support_) if selected]\n",
    "\n",
    "        # Create pipeline with selected features\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', XGBClassifier(random_state=RANDOM_STATE, **cleaned_params))\n",
    "        ])\n",
    "\n",
    "        # Evaluate model\n",
    "        metrics, conf_matrix, feature_imp = evaluate_optimized_model(\n",
    "            pipeline, df, selected_features, target, n_splits=CV_SPLITS, threshold=0.5)\n",
    "\n",
    "        results.append({\n",
    "            'n_features': n_features,\n",
    "            'selected_features': selected_features,\n",
    "            'metrics': metrics,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'feature_importance': feature_imp\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "def plot_rfe_results(rfe_results):\n",
    "    \"\"\"\n",
    "    Plot metrics across different feature set sizes.\n",
    "    \"\"\"\n",
    "    n_features = [r['n_features'] for r in rfe_results]\n",
    "    pr_auc = [r['metrics']['pr_auc'] for r in rfe_results]\n",
    "    precisions = [r['metrics']['precision'] for r in rfe_results]\n",
    "    recalls = [r['metrics']['recall'] for r in rfe_results]\n",
    "    f1_scores = [r['metrics']['f1'] for r in rfe_results]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax.plot(n_features, pr_auc, marker='o', label='PR-AUC')\n",
    "    ax.plot(n_features, precisions, marker='o', label='Precision')\n",
    "    ax.plot(n_features, recalls, marker='o', label='Recall')\n",
    "    ax.plot(n_features, f1_scores, marker='o', label='F1 Score')\n",
    "\n",
    "    ax.set_xlabel('Number of Features')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Model Performance vs Number of Features')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add vertical lines at each data point for easier reading\n",
    "    for x in n_features:\n",
    "        ax.axvline(x=x, color='gray', linestyle=':', alpha=0.3)\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Example usage\n",
    "n_features = [10, 15, 20, 30, 50, 75, 100]\n",
    "print(\"Performing Recursive Feature Elimination analysis with optimized parameters...\")\n",
    "rfe_results = perform_rfe_analysis(df_processed, features, target, n_features)\n",
    "\n",
    "# Find best feature set based on PR-AUC score\n",
    "best_result = max(rfe_results, key=lambda x: x['metrics']['pr_auc'])\n",
    "print(\"\\nBest feature set results:\")\n",
    "print(f\"Number of features: {best_result['n_features']}\")\n",
    "\n",
    "print(\"\\nRFE Adjusted Model Performance Metrics:\")\n",
    "for metric, value in best_result['metrics'].items():\n",
    "    print(f\"{metric}: {value:.6f}\")\n",
    "\n",
    "# Plot results\n",
    "fig_metrics = plot_rfe_results(rfe_results)\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix and feature importance for best model\n",
    "fig_results = plot_results(\n",
    "    best_result['confusion_matrix'],\n",
    "    best_result['feature_importance']\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82774c93",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avgtemp_c',\n",
       " 'deepsea_loiter_freq_365D',\n",
       " 'destination_port_port_capacity',\n",
       " 'event_info_destination_port.iso_CHN',\n",
       " 'event_info_destination_port.iso_ESP',\n",
       " 'event_info_destination_port.iso_IDN',\n",
       " 'event_info_destination_port.iso_JPN',\n",
       " 'event_info_destination_port.iso_KOR',\n",
       " 'event_info_destination_port.iso_RUS',\n",
       " 'event_info_destination_port.iso_USA',\n",
       " 'event_info_distance_from_port_m',\n",
       " 'event_info_distance_from_shore_m',\n",
       " 'event_info_origin_port.iso_NOR',\n",
       " 'event_info_origin_port.iso_RUS',\n",
       " 'maxwind_kph',\n",
       " 'origin_destination_distance',\n",
       " 'origin_port_port_capacity',\n",
       " 'port_congestion',\n",
       " 'port_loiter_freq_30D',\n",
       " 'port_loiter_freq_90D',\n",
       " 'prev_avg_deepsea_loiter_dur',\n",
       " 'prev_avg_distance_travelled',\n",
       " 'prev_avg_port_loiter_dur',\n",
       " 'prev_loitering_type',\n",
       " 'start_dayofweek',\n",
       " 'start_hour',\n",
       " 'start_month',\n",
       " 'time_since_last_loiter',\n",
       " 'vessel_info_flag_BHS',\n",
       " 'vessel_info_flag_PAN']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_result['selected_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b732d6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Refining - Iteration 3: Parameter Adjustment\n",
    "Adjusting model parameters by using wider range for Randmonized CV Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949f18b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                           f1_score, roc_auc_score, average_precision_score,\n",
    "                           confusion_matrix)\n",
    "\n",
    "\n",
    "def adjusted_xgb_model(df, features, target, n_splits=CV_SPLITS, n_iter=100):\n",
    "    \"\"\"\n",
    "    Adjusted parameters of Gradient Boosting model\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X = df[features].values\n",
    "    y = df[target].values\n",
    "\n",
    "    # Define parameter space\n",
    "    param_distributions = {\n",
    "        'classifier__n_estimators': randint(100, 1000),               # Number of boosting rounds\n",
    "        'classifier__learning_rate': uniform(0.01, 0.3),              # Step size shrinkage\n",
    "        'classifier__max_depth': randint(3, 15),                      # Maximum tree depth\n",
    "        'classifier__subsample': uniform(0.5, 0.5),                   # Subsample ratio of the training data\n",
    "        'classifier__colsample_bytree': uniform(0.5, 0.5),            # Subsample ratio of columns\n",
    "        'classifier__scale_pos_weight': [float(np.sum(y == 0)) / np.sum(y == 1)], # Class weight scaling\n",
    "        'classifier__gamma': uniform(0, 5),                           # Minimum loss reduction to split\n",
    "        'classifier__min_child_weight': randint(1, 10),               # Minimum sum of instance weight\n",
    "        'classifier__reg_alpha': uniform(0, 1),                       # L1 regularization term\n",
    "        'classifier__reg_lambda': uniform(1, 10)                      # L2 regularization term\n",
    "}\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', XGBClassifier(random_state=RANDOM_STATE, eval_metric='logloss'))\n",
    "    ])\n",
    "\n",
    "    # Initialize TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    # Initialize RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        cv=tscv,\n",
    "        scoring='average_precision',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fit RandomizedSearchCV\n",
    "    random_search.fit(X, y)\n",
    "\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "\n",
    "# After getting best_model:\n",
    "print(\"Getting Parameter adjusted XGBoost model...\")\n",
    "best_model, best_params = adjusted_xgb_model(df_processed, best_result['selected_features'], target)\n",
    "\n",
    "print(\"\\nBest parameters found:\")\n",
    "for param, value in best_params.items():\n",
    "    clean_param = param.replace('classifier__', '')\n",
    "    print(f\"{clean_param}: {value}\")\n",
    "\n",
    "print(\"\\nEvaluating optimized model...\")\n",
    "metrics, conf_matrix, feature_importance = evaluate_optimized_model(\n",
    "    best_model,\n",
    "    df_processed,\n",
    "    best_result['selected_features'],\n",
    "    target,\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "# Display final results\n",
    "print(\"Parameter adjusted Model Performance Metrics:\")\n",
    "print(metrics)\n",
    "\n",
    "# Plot final results\n",
    "fig = plot_results(conf_matrix, feature_importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1bbc0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Refining - Iteration 4: Decision Threshold Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd628521",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                           f1_score, roc_auc_score, average_precision_score,\n",
    "                           confusion_matrix)\n",
    "\n",
    "# After getting best_model:\n",
    "print(\"Optimizing XGBoost model...\")\n",
    "best_model, best_params = adjusted_xgb_model(df_processed, best_result['selected_features'], target)\n",
    "\n",
    "print(\"\\nBest parameters found:\")\n",
    "for param, value in best_params.items():\n",
    "    clean_param = param.replace('classifier__', '')\n",
    "    print(f\"{clean_param}: {value}\")\n",
    "\n",
    "# Decision Threshold testing range\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "threshold_results = {}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    metrics, conf_matrix, feature_importance = evaluate_optimized_model(\n",
    "        best_model,\n",
    "        df_processed,\n",
    "        best_result['selected_features'],\n",
    "        target,\n",
    "        threshold=threshold\n",
    "    )\n",
    "    threshold_results[threshold] = {\n",
    "        'metrics': metrics,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "# Convert threshold results to a DataFrame for cleaner printing and plotting\n",
    "threshold_metrics_df = pd.DataFrame({\n",
    "    threshold: results['metrics'] for threshold, results in threshold_results.items()\n",
    "}).T\n",
    "print(\"\\nResults for different thresholds (metrics by threshold):\")\n",
    "print(threshold_metrics_df)\n",
    "\n",
    "# Plot threshold metrics side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Precision-Recall trade-off\n",
    "threshold_metrics_df[['precision', 'recall']].plot(ax=ax1, marker='o')\n",
    "ax1.set_title('Precision-Recall vs Threshold')\n",
    "ax1.set_xlabel('Threshold')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.legend(title=\"Metrics\")\n",
    "\n",
    "# F1 Score and MCC\n",
    "threshold_metrics_df[['f1', 'pr_auc']].plot(ax=ax2, marker='o')\n",
    "ax2.set_title('F1 Score and PR-AUC vs Threshold')\n",
    "ax2.set_xlabel('Threshold')\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.legend(title=\"Metrics\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5f0ec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating optimized model with best threshold...\")\n",
    "metrics, conf_matrix, feature_importance = evaluate_optimized_model(\n",
    "    best_model,\n",
    "    df_processed,\n",
    "    best_result['selected_features'],\n",
    "    target,\n",
    "    threshold=0.4)\n",
    "\n",
    "print(\"\\nOptimized Model Performance Metrics (with best threshold):\")\n",
    "print(metrics)\n",
    "\n",
    "fig = plot_results(conf_matrix, feature_importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07dd06e-fdbc-4d57-89d6-30a2ea758625",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Testing model on geographic regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10e7fc7d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model by geographic region...\n",
      "\n",
      "Model Performance by Region:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "North East Asia (Sample size: 5858)\n",
      "----------------------------------------\n",
      "accuracy: 0.9063\n",
      "precision: 0.4278\n",
      "recall: 0.8910\n",
      "f1: 0.5780\n",
      "pr_auc: 0.7964\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4933  503]\n",
      " [  46  376]]\n",
      "----------------------------------------\n",
      "\n",
      "South East Asia (Sample size: 389)\n",
      "----------------------------------------\n",
      "accuracy: 0.5990\n",
      "precision: 0.3699\n",
      "recall: 0.9891\n",
      "f1: 0.5385\n",
      "pr_auc: 0.8951\n",
      "\n",
      "Confusion Matrix:\n",
      "[[142 155]\n",
      " [  1  91]]\n",
      "----------------------------------------\n",
      "\n",
      "Europe (Sample size: 680)\n",
      "----------------------------------------\n",
      "accuracy: 0.8426\n",
      "precision: 0.3697\n",
      "recall: 0.9531\n",
      "f1: 0.5328\n",
      "pr_auc: 0.8642\n",
      "\n",
      "Confusion Matrix:\n",
      "[[512 104]\n",
      " [  3  61]]\n",
      "----------------------------------------\n",
      "\n",
      "West/South Africa (Sample size: 811)\n",
      "----------------------------------------\n",
      "accuracy: 0.8483\n",
      "precision: 0.4020\n",
      "recall: 0.9524\n",
      "f1: 0.5654\n",
      "pr_auc: 0.8923\n",
      "\n",
      "Confusion Matrix:\n",
      "[[608 119]\n",
      " [  4  80]]\n",
      "----------------------------------------\n",
      "\n",
      "Panama Canal (Sample size: 204)\n",
      "----------------------------------------\n",
      "accuracy: 0.7941\n",
      "precision: 0.3115\n",
      "recall: 1.0000\n",
      "f1: 0.4750\n",
      "pr_auc: 0.8954\n",
      "\n",
      "Confusion Matrix:\n",
      "[[143  42]\n",
      " [  0  19]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def define_geographic_regions(lat, lon):\n",
    "    \"\"\"\n",
    "    Define geographic regions based on latitude and longitude coordinates\n",
    "    \"\"\"\n",
    "    if (20 <= lat <= 70) and (115 <= lon <= 155):  # North East Asia\n",
    "        return 'North East Asia'\n",
    "    elif (-15 <= lat <= 19) and (115 <= lon <= 170):  # South East Asia\n",
    "        return 'South East Asia'\n",
    "    elif (30 <= lat <= 75) and (-15 <= lon <= 40):  # Europe\n",
    "        return 'Europe'\n",
    "    elif (-45 <= lat <= 29) and (-30 <= lon <= 60):  # West and South Africa\n",
    "        return 'West/South Africa'\n",
    "    elif (-20 <= lat <= 30) and (-110 <= lon <= -45):  # Panama Canal\n",
    "        return 'Panama Canal'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "def evaluate_model_by_region(model, test_data, features, target, threshold=0.4):\n",
    "    \"\"\"\n",
    "    Evaluate trained model on new unseen data split by geographic regions\n",
    "    \"\"\"\n",
    "    # Add region column to test data\n",
    "    test_data['region'] = test_data.apply(\n",
    "        lambda row: define_geographic_regions(row['lat_mean'], row['lon_mean']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store results for each region\n",
    "    regional_results = {}\n",
    "    \n",
    "    # Evaluate for each region\n",
    "    for region in ['North East Asia', 'South East Asia', 'Europe', \n",
    "                  'West/South Africa', 'Panama Canal']:\n",
    "        # Filter data for current region\n",
    "        region_data = test_data[test_data['region'] == region]\n",
    "        \n",
    "        if len(region_data) == 0:\n",
    "            print(f\"No data points found for {region}\")\n",
    "            continue\n",
    "            \n",
    "        # Get features and true values for region\n",
    "        X_region = region_data[features].values\n",
    "        y_true = region_data[target].values\n",
    "        \n",
    "        # Get probability predictions\n",
    "        y_pred_proba = model.predict_proba(X_region)[:, 1]\n",
    "        # Apply threshold to get final predictions\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'sample_size': len(region_data),\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred),\n",
    "            'recall': recall_score(y_true, y_pred),\n",
    "            'f1': f1_score(y_true, y_pred),\n",
    "            'pr_auc': average_precision_score(y_true, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        # Store results\n",
    "        regional_results[region] = {\n",
    "            'metrics': metrics,\n",
    "            'confusion_matrix': conf_matrix\n",
    "        }\n",
    "    \n",
    "    return regional_results\n",
    "\n",
    "def print_regional_results(regional_results):\n",
    "    \"\"\"\n",
    "    Print evaluation metrics for each region in a formatted way\n",
    "    \"\"\"\n",
    "    print(\"\\nModel Performance by Region:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for region, results in regional_results.items():\n",
    "        print(f\"\\n{region} (Sample size: {results['metrics']['sample_size']})\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Print metrics\n",
    "        metrics = results['metrics']\n",
    "        for metric in ['accuracy', 'precision', 'recall', 'f1', 'pr_auc']:\n",
    "            print(f\"{metric}: {metrics[metric]:.4f}\")\n",
    "        \n",
    "        # Print confusion matrix\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(results['confusion_matrix'])\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# # Load and preprocess unseen (2024) test data\n",
    "# test_data = pd.read_csv('data/cleaned_testing_data/testing_data.csv')\n",
    "# test_df_processed, test_features, test_target = preprocess_data(test_data)\n",
    "\n",
    "# Load and preprocess main dataset\n",
    "test_data = pd.read_csv('data/final_data/final_data.csv')\n",
    "test_df_processed, test_features, test_target = preprocess_data(test_data)\n",
    "\n",
    "# Evaluate model by region\n",
    "print(\"Evaluating model by geographic region...\")\n",
    "regional_results = evaluate_model_by_region(\n",
    "    best_model,  # Your trained model from previous steps\n",
    "    test_df_processed,\n",
    "    best_result['selected_features'],\n",
    "    test_target,\n",
    "    threshold=0.4\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print_regional_results(regional_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c248d25-c515-4cd9-a6a5-8dd533f2f884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
